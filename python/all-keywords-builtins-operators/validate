#!/usr/bin/env python3
import unittest
import keyword
import operator
import re
import tokenize
from io import StringIO


PANGRAM_FILE="pangram.py"


####################################################################################################

# Begin constructing a list of all unique and valid Python source lexemes in string form

python_lexemes = set()

# Get keywords, i.e. reserved words
for kw in keyword.kwlist:
	python_lexemes.add(kw)

# Get builtin function names like "len" and "sorted"
for bi in __builtins__.__dict__.keys():
	python_lexemes.add(bi)

# Get all operator text symbols, such as |=, ~, >>= etc.
operator_function_regex = re.compile(r"Same as (.+)\.")
non_word_regex = re.compile('[^\W\s]')

for name, val in operator.__dict__.items():
	if callable(val):
		try:
			operator_string = non_word_regex.sub('', operator_function_regex.findall(val.__doc__)[0] )
			for op in operator_string.split():
				python_lexemes.add(op)
		except:
			pass

# Symbols not in operator module :)
python_lexemes.add(":=")
python_lexemes.add("'") 
python_lexemes.add('"') 
python_lexemes.add('"""') 


# Also satisfy all tokenizer regex cases (this will capture things like hex-numbers, bin-numbers, 
# and string prefixes like f,b,r, etc.)
from token import tok_name
CamelCaseRegex = re.compile(r'[A-Z][a-z]+[A-Z]*[a-z]*')

tokenize_dir = " ".join(dir(tokenize))

token_regex_strings = { t : rg for t in CamelCaseRegex.findall(tokenize_dir) if isinstance((rg:=getattr(tokenize, t)),str) }

####################################################################################################

# Get the lexemes from the file for evaluation of exhaustiveness

with open(PANGRAM_FILE, 'r') as pf:
	pangram_raw_body = pf.read()

pangram_body = pangram_raw_body

# Contents of strings do not count towards the goal :)
apostrophe_3_regular_string_regex = re.compile(r"(?<!\w)'''[^'\n]+'''")
quote_3_regular_string_regex = re.compile(r'(?<!\w)"""[^"\n]+"""')

apostrophe_regular_string_regex = re.compile(r"(?<!\w)'[^'\n]+'")
quote_regular_string_regex = re.compile(r'(?<!\w)"[^"\n]+"')

pangram_body = quote_3_regular_string_regex.sub('""', pangram_body)
pangram_body = apostrophe_3_regular_string_regex.sub('""', pangram_body)

pangram_body = quote_regular_string_regex.sub('""', pangram_body)
pangram_body = apostrophe_regular_string_regex.sub('""', pangram_body)



####################################################################################################

# Run test suite to validate authenticity of pangram

import unittest
import trace
import sys
import runpy
import os


stdout_streams={}
stderr_streams={}

# Standard lib modules don't seem to expose a better API for capturing outputs to string
def capture_descriptor_output(f):
	def pipe_descriptor_to_stream_and_return(*args):
		global stdout_streams
		global stderr_streams 
		temp_out = StringIO() 
		temp_err = StringIO() 
		sys.stdout = temp_out 
		sys.stderr = temp_err 
		f(*args)
		sys.stdout = sys.__stdout__  
		sys.stderr = sys.__stderr__  
		stdout_streams[f.__name__] = temp_out.getvalue()
		stderr_streams[f.__name__] = temp_err.getvalue()
	return pipe_descriptor_to_stream_and_return



class TestPangramAuthenticity(unittest.TestCase):
	
	
	@capture_descriptor_output
	def test_pangram_runs_successfully(self): 
		global pangram_body
		try:

			module_name = PANGRAM_FILE.partition('.py')[0]
			mod_name, mod_spec, code = runpy._get_module_details(module_name)
			sys.argv = [code.co_filename]
			globs = {
					'__name__': '__main__',
					'__file__': code.co_filename,
					'__package__': mod_spec.parent,
					'__loader__': mod_spec.loader,
					'__spec__': mod_spec,
					'__cached__': None,
			}
			tracer = trace.Trace(ignoredirs=[sys.prefix, sys.exec_prefix], trace=1, count=1)
			code = compile(pangram_raw_body, PANGRAM_FILE, 'exec')
			tracer.runctx(code, globs,globs)
			tracer.results().write_results(show_missing=True, summary=False, coverdir=os.devnull)

		except Exception:
				self.fail("\n\n\t\tPangram did not successfully execute")


	@capture_descriptor_output
	def test_pangram_has_all_python_lexemes(self):
		global pangram_body
		global python_lexemes
		for l in python_lexemes:
			self.assertIn(l, pangram_body, msg=f"\n\n\t\t'{l}' not present in {PANGRAM_FILE}.")


	@capture_descriptor_output
	def test_token_regex_machines_all_find_matches(self):
		global token_regex_strings
		global pangram_body
		for regex_name, regex in token_regex_strings.items():
			self.assertRegex(pangram_body, regex, msg=f"\n\n\t\tRegex '{regex_name}' := /{regex}/ did not produce a match.")


@capture_descriptor_output
def run_tests():
	unittest.main(exit=False)

if __name__ == '__main__':
	run_tests()

	def colorize(s: str, r: str, c: int) -> str:
		return s.replace(r, f'\033[3{c}m{r}\033[0m')

	# line_trace_regex = re.compile( rf"({PANGRAM_FILE}\(\d+\):)" )
	summary, linebreak, results = stderr_streams['run_tests'].split("\n",2)

	summary = colorize(summary, '.', 2)
	summary = colorize(summary, 'F', 1)


	if results.startswith("FAIL"):
		
		result_lines=re.compile(r"\n[=\-]+\n").split(results)
		for i in range(1,len(result_lines),2):
			result_lines[i] = "\n------------------" + result_lines[i].split("\n\n\t\t")[-1] + "\n\n\n==================\n"


		results = "".join(result_lines)

		failure_colorize_regex = re.compile( r'(\=*\n?FAIL:) (.+)\n(-*)')
		results = failure_colorize_regex.sub(r"\033[31m\1 \033[33m\2\n\033[31m\3\033[0m\n", "==================\n"+results)

		print(summary+"\n\n")
		print(results)
	else:
		
		line_trace_regex = re.compile( rf"({PANGRAM_FILE}\(\d+\):)" )
		stdout = line_trace_regex.sub(r"\033[34m\1\033[0m", stdout_streams['test_pangram_runs_successfully'])
		stdout = stdout.replace("--- modulename:", "\033[33m--- modulename:\033[0m")
		print(stdout)
		print(summary+"\n")
		print(colorize(results,"OK",2) )
